{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "from math import isnan\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions and global variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable\n",
    "cambridge_url = 'https://dictionary.cambridge.org'\n",
    "oxford_url = 'https://www.oxfordlearnersdictionaries.com'\n",
    "header = ['Vocabulary', 'Type', 'Cloze', 'Phonetic', 'Audio', 'English meaning', 'Vietnamese meaning', 'Example']\n",
    "['Type', 'Cloze', 'Phonetic', 'Audio', 'English meaning', 'Example']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium Driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chrome driver\n",
    "def initialize_driver(): \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    download_path = r'/Users/btp712/Code/Anki crawler/audio/'\n",
    "    prefs={\"profile.managed_default_content_settings.images\": 2, 'disk-cache-size': 4096,\n",
    "           \"download.default_directory\": download_path}\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs) # Manage image loading and run on disk cache\n",
    "    # chrome_options.add_argument(\"--headless\") # Runs Chrome in headless mode\n",
    "    chrome_options.add_argument('--no-sandbox') # Bypass OS security model\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage') # overcome limited resource problems\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initalize_request(url, headers=({'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/12.0'})):\n",
    "    return requests.get(url=url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary_page_source(url):\n",
    "    response = initalize_request(url)\n",
    "\n",
    "    soup = None\n",
    "    status = False\n",
    "    if response.status_code == 200 and response.url == url:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        status = True\n",
    "\n",
    "    return soup, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_panel_by_type(word, word_type=None, dictionary_url=cambridge_url):\n",
    "    word_page_url = cambridge_url + r'/dictionary/english/' + word.replace(' ', '-').lower()\n",
    "    word_page_src, status_code = get_dictionary_page_source(word_page_url)\n",
    "\n",
    "    if not status_code:\n",
    "        return None\n",
    "    \n",
    "    # select panel by word types\n",
    "    word_panels = word_page_src.find_all('div', {'class': 'pr dictionary',\n",
    "                                                 'role': 'tabpanel'})\n",
    "    res_panel = word_panels[0]\n",
    "    if word_type:\n",
    "        for panel in word_panels:\n",
    "            type = panel.find('span', {'class': 'pos dpos'}).get_text()\n",
    "            if type == word_type:\n",
    "                return panel\n",
    "    \n",
    "    return res_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sound(soup, file_path, dictionary_url=cambridge_url, included_pattern=None):\n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    # get all download source\n",
    "    source_tags = soup.find_all('source')\n",
    "    download_url = source_tags[0]['src']\n",
    "    if included_pattern:\n",
    "        for tag in source_tags:\n",
    "            if re.search(included_pattern, tag['src']):\n",
    "                download_url = tag['src']\n",
    "                break\n",
    "             \n",
    "    download_url = dictionary_url + download_url\n",
    "\n",
    "    download_response = initalize_request(download_url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(download_response.content)\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phonetic(soup):\n",
    "    phonetic = None\n",
    "    phonetic_tags = soup.find_all('span', {'class': 'pron dpron'})\n",
    "    if phonetic_tags:\n",
    "        return phonetic_tags[1].get_text()\n",
    "    \n",
    "    return phonetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_english_meaning(soup):\n",
    "    meaning = soup.find('div', 'def ddef_d db').get_text().strip()\n",
    "    if not meaning[-1].isalpha():\n",
    "        meaning = meaning[:-1]\n",
    "    \n",
    "    return meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(soup):\n",
    "    examples_box = soup.find('div', 'def-body ddef_b')\n",
    "    if not examples_box:\n",
    "        return None\n",
    "    \n",
    "    examples = examples_box.find_all('div', 'examp dexamp')\n",
    "    res = []\n",
    "    for exp in examples:\n",
    "        use_case = exp.find('span', 'lu dlu')\n",
    "        exp_sentence = exp.find('span', 'eg deg').get_text()\n",
    "\n",
    "        complete_exp_sentence = '- '\n",
    "        if use_case:\n",
    "            complete_exp_sentence += f'({use_case.get_text()}) | '\n",
    "        \n",
    "        complete_exp_sentence += exp_sentence + '\\n\\n'\n",
    "        res.append(complete_exp_sentence)\n",
    "\n",
    "    return ''.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(soup):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phonetic_sound_engmean_examples(vocabs_arr, dictionary_url=cambridge_url):\n",
    "    res_ipa = []\n",
    "    res_sound = []\n",
    "    res_eng_mean = []\n",
    "    res_example = []\n",
    "\n",
    "    for vocab in vocabs_arr:\n",
    "        vocab_page_url = cambridge_url + r'/dictionary/english/' + vocab.replace(' ', '-').lower()\n",
    "        page_src, status = get_vocabPageSrc(vocab_page_url)\n",
    "\n",
    "        if status:\n",
    "            res_ipa.append(None)\n",
    "            res_sound.append(None)\n",
    "            res_eng_mean.append(None)\n",
    "            res_example.append('')\n",
    "            continue\n",
    "        \n",
    "        # get phonetic\n",
    "        phonetic = None\n",
    "        if page_src.find('span', 'pron dpron'): phonetic = page_src.find('span', 'pron dpron').text\n",
    "        res_ipa.append(phonetic)\n",
    "\n",
    "        # get sound\n",
    "        filepath = os.getcwd() + r'/../data/audio/' + vocab + '.mp3'\n",
    "        res_sound.append('[sound:' + filepath + ']')\n",
    "        get_sound(page_src, filepath)\n",
    "\n",
    "        # get english meaming & examples\n",
    "        definition_box = page_src.find('div', class_='def-block ddef_block')\n",
    "        eng_mean = definition_box.find('div', 'def ddef_d db').text.strip()\n",
    "        if eng_mean[-1] != '.' and not eng_mean[-1].isalpha():\n",
    "            eng_mean = eng_mean[:-1]\n",
    "        res_eng_mean.append(eng_mean)\n",
    "        examples_src = definition_box.find_all('div', 'examp dexamp')\n",
    "        \n",
    "        examples = ''\n",
    "        for example in examples_src:\n",
    "            if examples != '': examples += '\\n\\n';\n",
    "            examples += '- ' + example.text.strip()\n",
    "\n",
    "        res_example.append(examples)\n",
    "\n",
    "    return res_ipa, res_sound, res_eng_mean, res_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cloze(word):\n",
    "    new_word = word[0] + re.sub('\\w', '_', word[1:])\n",
    "\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_wordType(short_wordType):\n",
    "    res = ''\n",
    "    if short_wordType == 'n': res = 'noun'\n",
    "    elif short_wordType == 'v': res = 'verb'\n",
    "    elif short_wordType == 'adj': res = 'adjective'\n",
    "    else: res = 'adverb'\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existane(entry, existed_df):\n",
    "    return ((existed_df.Vocabulary == entry.Vocabulary) & (existed_df.Type == entry.Type)).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(vocabs_df, existed_path=None):\n",
    "    vocabs_df['Vocabulary'] = vocabs_df.Vocabulary.apply(lambda x : x.lower(), axis=1)\n",
    "    vocabs_df['Type'] = vocabs_df['Type'].apply(create_full_wordsType, 0)\n",
    "    need2Import_df = vocabs_df.copy()\n",
    "    if existed_path:\n",
    "        existed_df = pd.read_csv(existed_path, names=header, index_col=False)\n",
    "        mask = vocabs_df.apply(lambda x : check_existane(x, existed_df), axis=1)\n",
    "        need2Import_df = vocabs_df.iloc[~mask.to_numpy()]\n",
    "\n",
    "    # crawl\n",
    "    ipa_arr, soundPath_arr, eng_mean_arr, example_arr = get_phonetic_sound_engmean_examples(need2Import_df.Vocabulary.values)\n",
    "\n",
    "    need2Import_df.insert(need2Import_df.shape[1], 'Cloze', need2Import_df['Vocabulary'].apply(create_cloze, 0))\n",
    "    need2Import_df.insert(need2Import_df.shape[1], 'Phonetic', ipa_arr)\n",
    "    need2Import_df.insert(need2Import_df.shape[1], 'Audio', soundPath_arr)\n",
    "    need2Import_df.insert(need2Import_df.shape[1], 'English meaning', eng_mean_arr)\n",
    "    need2Import_df.insert(need2Import_df.shape[1], 'Example', example_arr)\n",
    "    \n",
    "    # merge & update\n",
    "    final_df = need2Import_df.copy()\n",
    "    if existed_path:\n",
    "        final_df = pd.merge(vocabs_df, existed_df, how='left', on=['Vocabulary', 'Type'])\n",
    "        start = 0\n",
    "        for i in range(len(mask)):\n",
    "            # update new words into the previous version\n",
    "            if not mask[i]:\n",
    "                for col in ['Cloze', 'Phonetic', 'Audio', 'English meaning', 'Example']:\n",
    "                    final_df.at[i, col] = need2Import_df.iloc[start][col]\n",
    "                start += 1\n",
    "\n",
    "            # update vietnamese meaning\n",
    "            if (\n",
    "                isinstance(final_df.iloc[i][\"Vietnamese meaning_y\"], str)\n",
    "                and final_df.iloc[i][\"Vietnamese meaning_x\"] != final_df.iloc[i][\"Vietnamese meaning_y\"]\n",
    "            ):\n",
    "                final_df.iloc[i][\"Vietnamese meaning_x\"] += \"\\n\" * 2 + final_df.iloc[i][\"Vietnamese meaning_y\"]\n",
    "    \n",
    "        # delete the abundant vietnamese meaning column and rename the another one\n",
    "        final_df.drop('Vietnamese meaning_y', axis=1, inplace=True)\n",
    "        final_df.rename(columns={'Vietnamese meaning_x':'Vietnamese meaning'}, inplace=True)\n",
    "\n",
    "\n",
    "        \n",
    "    return need2Import_df, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_crawl(df, index, url):\n",
    "    # fill phonetic, english meaning and vietnamese meaning\n",
    "    phonetic = audio_path = eng_mean = None\n",
    "    examples = []\n",
    "\n",
    "    page_src, status = get_vocabPageSrc(url)\n",
    "    if status:\n",
    "        return\n",
    "        \n",
    "    # get phonetic\n",
    "    phonetic = page_src.find('span', 'pron dpron').text\n",
    "\n",
    "    # get sound\n",
    "    filepath = os.getcwd() + r'/data/audio/' + df.iloc[index].vocabulary + '.mp3'\n",
    "    audio_path = ('[sound:' + filepath + ']')\n",
    "    get_sound(page_src, filepath)\n",
    "\n",
    "    # get english meaming & examples\n",
    "    definition_box = page_src.find('div', class_='def-block ddef_block')\n",
    "    eng_mean = definition_box.find('div', 'def ddef_d db').text.strip()\n",
    "    if eng_mean[-1] != '.' and not eng_mean[-1].isalpha():\n",
    "        eng_mean = eng_mean[:-1]\n",
    "    examples_src = definition_box.find_all('div', 'examp dexamp')\n",
    "    \n",
    "    examples = ''\n",
    "    for example in examples_src:\n",
    "        if examples != '': examples += '\\n\\n';\n",
    "        examples += '- ' + example.text.strip()\n",
    "\n",
    "    return phonetic, audio_path, eng_mean, examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs_df = pd.read_csv(input('Path to new vocabularies file: '))\n",
    "existed_path = input('Path to lasted file (if this is the first file, please enter 0): ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need2Import_df, final_df = crawl(vocabs_df, existed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape, need2Import_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reodered_cols = ['Vocabulary', 'Type', 'Cloze', 'Phonetic', 'Audio', 'English meaning', 'Vietnamese meaning', 'Example']\n",
    "need2Import_df = need2Import_df[reodered_cols]\n",
    "final_df = final_df[reodered_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported = input('Do you want to export to file (yes/no): ')\n",
    "\n",
    "assert exported == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in {'lasted file': (final_df, r'../crawled_data/'), '2Import_df': (need2Import_df, r'../new2import_data/')}.items():\n",
    "    exported_filepath = input(f'Your {k} name:')\n",
    "    df, exported_folder = v\n",
    "    \n",
    "    filepath = exported_folder + exported_filepath\n",
    "    if os.path.isfile(filepath + '.csv'):\n",
    "        filepath += str(datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "\n",
    "    df.to_csv(filepath + '.csv', sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re - crawl\n",
    "\n",
    "In this section, we will recrawl words that can not be crawled in previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input('Do you want to re-crawl (yes/no): ') == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_values = re_crawl(vocabs_df, 1, r'https://dictionary.cambridge.org/vi/dictionary/english/stepfamily?q=step+family')\n",
    "update_params = ['Phonetic', 'Audio', 'English meaning', 'Example']\n",
    "\n",
    "for i in range(4):\n",
    "    vocabs_df.at[1, update_params[i]] = update_values[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
